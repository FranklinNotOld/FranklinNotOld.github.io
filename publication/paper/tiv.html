<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Publication</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../../assets/css/main.css" />
		<style>
            /* Flex container styles */
            .container {
                display: flex;
                justify-content: space-between;
                align-items: center;
            }
            
            /* Text container styles */
            .text-container {
                flex: 1;
                text-align: justify;
            }
            
            /* Image container styles */
            .image-container {
                flex: 0 0 auto; /* Prevent image container from growing */
            }
            
            /* Image styles */
            .image-container img {
                max-width: 450px; /* Adjust width as needed */
                height: auto; /* Maintain aspect ratio */
                border-radius: 8px; /* Optional: add rounded corners */
                margin-left: 25px; /* Space between text and image */
            }
        </style>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
                            <header id="header">
                                <a href="self.html" class="logo"><strong>Yongkang Li </strong> homepage</a>
                            </header>
                        
                        	<!-- Banner -->
                            <section id="banner">
                                <div class="content">
                                    <header>
                                        <h1 style="font-size: 36px;">A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving</h1>
                                    </header>
									<div style="font-size: 16px;">Haicheng Liao*, Yongkang Li*, Zhenning Li†, Shengbo Eben Li, Senior Member, IEEE, and Chengzhong Xu†, Fellow, IEEE</div>
                                </div>
                            </section>
                            <!-- <hr style="border-style: dashed; margin-top: -35px;" class="major" /> -->

							<!-- Section -->
							<section >
								<div>
									<header class="main">
										<h1 id="abstract" style="font-size: 28px; margin-top: -20px; margin-bottom: 5px;">Abstract</h1>
									</header>

									<span class="image fit">
										<img src="../../images/paper/tiv-head.jpg" alt="" style="width: 60%; display: block; margin: 0 auto;"/>
									</span>
									
									
									<p style="font-size: 16px;" style="width: 100%;">
										In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency. 
										Incorporating human decision-making insights enables AVs to more effectively anticipate the potential actions of other vehicles, significantly improving prediction accuracy and responsiveness in dynamic environments. 
										This paper introduces the Human-Like Trajectory Prediction (HLTP) model, which adopts a teacher-student knowledge distillation framework inspired by human cognitive processes. 
										The HLTP model incorporates a sophisticated teacher-student knowledge distillation framework. The "teacher" model, equipped with an adaptive visual sector, 
										mimics the visual processing of the human brain, particularly the functions of the occipital and temporal lobes. The "student" model focuses on real-time interaction and decision-making, 
										drawing parallels to prefrontal and parietal cortex functions. This approach allows for dynamic adaptation to changing driving scenarios, capturing essential perceptual cues for accurate prediction. 
										Evaluated using the Macao Connected and Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD benchmarks, HLTP demonstrates superior performance compared to existing models, 
										particularly in challenging environments with incomplete data. The project page is available at <a href="https://github.com/Petrichor625/HLTP" target="_blank">Link</a>.
									</p>
								</div>								
								
							</section>

							<!-- Section -->
							<section>
								<div>
									<header>
										<h1 id="model-structure" style="font-size: 28px; margin-top: -20px; margin-bottom: 10px;">Model Structure</h1>
									</header>
								</div>
								<div style="width: 100%;">
									<span class="image fit">
										<img src="../../images/paper/tiv-structure.png" alt="" style="width: 100%; display: block; margin: 0 auto;"/>
									</span>
								</div>																																			
								<p style="font-size: 16px;">
									Overview of the Model Structure:</p>

									<p style="font-size: 16px;">1. <b>Teacher-Student Knowledge Distillation Framework</b>: </p>
									<ul>
										<li style="font-size: 16px;"><b>The Teacher Model</b>: This model simulates the human visual observation process by integrating an adaptive visual sector and a surround-aware encoder. The adaptive visual sector mimics the human brain's visual processing, 
											particularly the occipital and temporal lobes, focusing on how drivers allocate attention based on speed and traffic conditions. The surround-aware encoder is designed to replicate peripheral vision, allowing the model to monitor the broader traffic environment.</li>
										<li style="font-size: 16px;"><b>The Student Model</b>: While the teacher model is powerful, it is computationally heavy. The student model is a lightweight version that learns from the teacher through knowledge distillation. 
											It focuses on real-time decision-making and interaction, similar to the functions of the prefrontal and parietal cortex in the human brain. The student model is designed to operate efficiently with fewer data inputs, making it suitable for real-time trajectory prediction.</li>
									</ul>
									
									<div class="container">
										<div class="text-container">
											<p style="font-size: 16px;">2. <b>Shift-Window Attention Block (SWA)</b>: This component is designed to mimic the selective attention mechanism of the human brain. It operates by focusing on local visual fields, much like how human vision selectively focuses on certain areas. 
												The SWA uses overlapping windows to ensure that the model captures detailed interaction between traffic participants.</p>
										</div>
										<div class="image-container">
											<span class="image fit">
												<img src="../../images/paper/tiv-swa.png" alt=""/>
											</span>
										</div>
									</div>

									<p style="font-size: 16px;">3. <b>Multimodal Decoder</b>:The Multimodal Decoder integrates visual and contextual information from the surround-aware and teacher encoders. It uses a transformer framework to handle sequential data and a Gaussian Mixture Model (GMM) for probabilistic trajectory prediction. 
										This approach allows the model to predict multiple possible future paths, considering different driving maneuvers, which enhances accuracy in dynamic traffic environments.
							</section>

							<!-- Section -->
							<section>
								<div>
									<header>
										<h1 id="experiment-result" style="font-size: 28px; margin-top: -20px; margin-bottom: 10px;">Experiment Result</h1>
									</header>
								</div>
								<p style="font-size: 16px;">Our comprehensive evaluation demonstrates HLTP's superior performance compared to SOTA baselines. HLTP's ``student'' model, trained on only 1.5 seconds of recent trajectory data, 
									surpasses the standard 3-second data reliance of baseline models. It notably achieves gains of 5.2% for short-term (2s) and 13.8% for long-term (5s) predictions on the NGSIM dataset. On the HighD dataset, all models, including HLTP, display fewer inaccuracies due to HighD's precise trajectories and larger data size. 
									While short-term predictions are comparable across models, HLTP excels in long-term forecasting with a 41.6% RMSE improvement for up to 5 seconds. In complex right-hand-drive environments like urban streets and unstructured roads (MoCAD dataset), 
									HLTP's accuracy gains range from 3.3% to 11.3%, underscoring its robustness and adaptability in diverse traffic scenarios.</p>
								<p style="font-size: 16px;">In our benchmark against SOTA baselines, HLTP and HLTP (s) models demonstrate superior performance across all metrics, while maintaining a minimal parameter count. 
									Despite limited access to many models' source codes, our analysis focuses on open-source options. Remarkably, HLTP (s) achieves high performance with significantly less complexity, reducing parameters by 71.41% and 55.89% compared to WSiP and CS-LSTM, respectively. 
									Furthermore, HLTP (s) efficiently outperforms transformer-based STDAN and CF-LSTM, using 82.34% and 77.79% fewer parameters, respectively. This highlights the efficiency and adaptability of our lightweight ``teacher-student" knowledge distillation framework, offering practitioners a balance between accuracy and computational resource requirements.</p>
								<div class="container">
									<div class="text-container">
										<p style="font-size: 16px;">Figure showcases the multimodal probabilistic prediction performance of HLTP on the NGSIM dataset, and the velocities of the target vehicle and its surrounding vehicles. The heat maps shown represent the Gaussian Mixture Model of predictions in challenging scenes. 
											These visualizations show that the highest probability predictions of our model are very close to the ground truth, indicating its impressive performance. Additionally, it also visually demonstrates our model's ability to accurately predict complex scenarios such as merging and lane changing, confirming its effectiveness in various traffic situations.</p>
									</div>
									<div class="image-container">
										<span class="image fit">
											<img src="../../images/paper/tiv-visualization.jpg" alt=""/>
										</span>
									</div>
								</div>
							</section>
						</div>
					</div>

					<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section>

								<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<!-- <li><a href="index.html">Homepage</a></li> -->
                                        <li>
											<a href="../../index.html" class="opener">Homepage</a>
											<ul>
												<li><a href="../../index.html#self-introduction">SELF-INTRODUCTION</a></li>
												<li><a href="../../index.html#news">NEWS</a></li>
												<li><a href="../../index.html#research">RESEARCH</a></li>
                                                <li><a href="../../index.html#software-copyright">SOFTWARE COPYRIGHT</a></li>
                                                <li><a href="../../index.html#project">PROJECT</a></li>
												<li><a href="../../index.html#scholarship-and-awards">SCHOLARSHIP AND AWARDS</a></li>
                                                <li><a href="../../index.html#leadership-and-activities">LEADERSHIP AND ACTIVITIES</a></li>
											</ul>
                                        </li>
                                        <li>
                                            <a href="publication/publication.html" class="opener">Publication</a>
											<ul>
												<li><a href="../publication.html#2024">2024</a></li>
                                                <ul>
                                                    <li><a href="mm24.html">When, Where, and What? A Benchmark for Accident Anticipation and Localization with Large Language Models</a></li>
                                                    <li><a href="ecai24.html">Less is More: Efficient Brain-Inspired Learning for Autonomous Driving Trajectory Prediction</a></li>
                                                    <li><a href="aap.html">Real-time Accident Anticipation for Autonomous Driving Through Monocular Depth-Enhanced 3D Modeling</a></li>
                                                    <li><a href="tiv.html">A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving</a></li>
                                                </ul>
												<li><a href="../publication.html#2023">2023</a></li>
                                                <ul>
                                                    <li><a href="#">Lightweight Human Observation-inspired Trajectory Prediction For Autonomous Driving</a></li>
                                                </ul>
											</ul>
										</li>
									</ul>
								</nav>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="../../assets/js/jquery.min.js"></script>
			<script src="../../assets/js/browser.min.js"></script>
			<script src="../../assets/js/breakpoints.min.js"></script>
			<script src="../../assets/js/util.js"></script>
			<script src="../../assets/js/main.js"></script>

	</body>
</html>